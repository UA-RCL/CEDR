//
// Copyright (c) 2018-2020 Manuel PÃ¶ter.
// Licensed under the MIT License. See LICENSE file in the project root for full license information.
//

#ifndef XENIUM_NIKOLAEV_QUEUE_HPP
#define XENIUM_NIKOLAEV_QUEUE_HPP

#include <xenium/parameter.hpp>
#include <xenium/policy.hpp>
#include <xenium/utils.hpp>

#include <xenium/detail/nikolaev_scq.hpp>

#include <atomic>
#include <cassert>
#include <cstdint>
#include <memory>

namespace xenium {
  /**
   * @brief An unbounded lock-free multi-producer/multi-consumer queue.
   * 
   * This implementation is based on the unbounded MPMC queue proposed by Nikolaev
   * \[[Nik19](index.html#ref-nikolaev-2019)\].
   * 
   * The nikoleav_queue provides lock-free progress guarantee under the condition that the
   * number of threads concurrently operating on the queue is less than the capacity of a node
   * (see `entries_per_node` policy).
   *
   * Supported policies:
   *  * `xenium::policy::reclaimer`<br>
   *    Defines the reclamation scheme to be used for internal nodes. (**required**)
   *  * `xenium::policy::entries_per_node`<br>
   *    Defines the number of entries for each internal node. This must be a power of two.
   *    (*optional*; defaults to 512)
   *  * `xenium::policy::pop_retries`<br>
   *    Defines the number of iterations to spin on a queue entry while waiting for a pending
   *    push operation to finish. (*optional*; defaults to 1000)
   *    Note: this policy is applied to the _internal_ queues. The Nikolaev queue internally
   *    uses two queues to manage the indexes of free/allocated slots. A push operation pops an
   *    item from the free queue, so this policy actually affects both, push and pop operations.
   *
   * @tparam T
   * @tparam Policies list of policies to customize the behaviour
   */
  template <class T, class... Policies>
  class nikolaev_queue {
  public:
    using value_type = T;
    using reclaimer = parameter::type_param_t<policy::reclaimer, parameter::nil, Policies...>;
    static constexpr unsigned pop_retries =
      parameter::value_param_t<unsigned, policy::pop_retries, 1000, Policies...>::value;
    static constexpr unsigned entries_per_node =
      parameter::value_param_t<unsigned, policy::entries_per_node, 512, Policies...>::value;

    static_assert(utils::is_power_of_two(entries_per_node), "entries_per_node must be a power of two");
    static_assert(parameter::is_set<reclaimer>::value, "reclaimer policy must be specified");

    template <class... NewPolicies>
    using with = nikolaev_queue<T, NewPolicies..., Policies...>;

    nikolaev_queue();
    ~nikolaev_queue();

    nikolaev_queue(const nikolaev_queue&) = delete;
    nikolaev_queue(nikolaev_queue&&) = delete;

    nikolaev_queue& operator= (const nikolaev_queue&) = delete;
    nikolaev_queue& operator= (nikolaev_queue&&) = delete;

    /**
     * @brief Pushes the given value.
     *
     * Progress guarantees: lock-free
     *
     * @param value
     */
    void push(value_type value);

    /**
     * @brief Tries to pop an element from the queue.
     *
     * Progress guarantees: lock-free
     *
     * @param result
     * @return `true` if the operation was successful, otherwise `false`
     */
    bool try_pop(value_type& result);

  private:
    struct node;

    using concurrent_ptr = typename reclaimer::template concurrent_ptr<node, 0>;
    using marked_ptr = typename concurrent_ptr::marked_ptr;
    using guard_ptr = typename concurrent_ptr::guard_ptr;

    using storage_t = typename std::aligned_storage<sizeof(T), alignof(T)>::type;

    static constexpr std::size_t remap_shift = detail::nikolaev_scq::calc_remap_shift(entries_per_node);
    
    // TODO - preallocate memory for storage and queues together with node
    struct node : reclaimer::template enable_concurrent_ptr<node> {
      node() :
        _storage(new storage_t[entries_per_node]),
        _allocated_queue(entries_per_node, remap_shift, detail::nikolaev_scq::empty_tag{}),
        _free_queue(entries_per_node, remap_shift, detail::nikolaev_scq::full_tag{})
      {}
      
      node(value_type&& value) :
        _storage(new storage_t[entries_per_node]),
        _allocated_queue(entries_per_node, remap_shift, detail::nikolaev_scq::first_used_tag{}),
        _free_queue(entries_per_node, remap_shift, detail::nikolaev_scq::first_empty_tag{})
      {
        new(&_storage[0]) T(std::move(value));
      }

      ~node() {
        std::uint64_t eidx;
        while (_allocated_queue.dequeue<false, pop_retries>(eidx, entries_per_node, remap_shift)) {
          reinterpret_cast<T&>(_storage[eidx]).~T();
        }
      }

      void steal_init_value(value_type& value) {
        bool success = try_pop(value);
        (void)success;
        assert(success);
      }

      bool try_push(value_type&& value) {
        std::uint64_t eidx;
        if (!_free_queue.dequeue<false, pop_retries>(eidx, entries_per_node, remap_shift)) {
          _allocated_queue.finalize();
          return false;
        }

        assert(eidx < entries_per_node);
        new(&_storage[eidx]) T(std::move(value));
        if (!_allocated_queue.enqueue<false, true>(eidx, entries_per_node, remap_shift)) {
          // queue has been finalized
          _free_queue.enqueue<false, false>(eidx, entries_per_node, remap_shift);
          return false;
        }
        return true;
      }

      bool try_pop(value_type& result) {
        std::uint64_t eidx;
        if (!_allocated_queue.dequeue<false, pop_retries>(eidx, entries_per_node, remap_shift))
          return false;

        assert(eidx < entries_per_node);
        T& data = reinterpret_cast<T&>(_storage[eidx]);
        result = std::move(data);
        data.~T();
        _free_queue.enqueue<false, false>(eidx, entries_per_node, remap_shift);
        return true;
      }

      std::unique_ptr<storage_t[]> _storage;
      detail::nikolaev_scq _allocated_queue;
      detail::nikolaev_scq _free_queue;

      concurrent_ptr _next;
    };

    concurrent_ptr _tail;
    concurrent_ptr _head;
  };

  template <class T, class... Policies>
  nikolaev_queue<T, Policies...>::nikolaev_queue() {
    auto n = new node();
    _tail.store(n, std::memory_order_relaxed);
    _head.store(n, std::memory_order_relaxed);
  }

  template <class T, class... Policies>
  nikolaev_queue<T, Policies...>::~nikolaev_queue() {
    auto h = _head.load(std::memory_order_relaxed).get();
    while (h != nullptr) {
      auto next = h->_next.load(std::memory_order_relaxed).get();
      delete h;
      h = next;
    }
  }
  
  template <class T, class... Policies>
  void nikolaev_queue<T, Policies...>::push(value_type value) {
    guard_ptr n;
    for (;;) {
      // (1) - this acquire-load synchronizes-with the release-CAS (3, 5)
      n.acquire(_tail, std::memory_order_acquire);
      if (n->_next.load(std::memory_order_relaxed) != nullptr) {
        // (2) - this acquire-load synchronizes-with the release-CAS (4)
        const auto next = n->_next.load(std::memory_order_acquire);
        marked_ptr expected = n;
        // (3) - this release-CAS synchrnoizes with the acquire-load (1)
        _tail.compare_exchange_weak(expected, next, std::memory_order_release, std::memory_order_relaxed);
        continue;
      }

      if (n->try_push(std::move(value)))
        return;

      auto next = new node(std::move(value));
      marked_ptr expected{nullptr};
      // (4) - this release-CAS synchronizes-with the acquire-load (2, 7)
      if (n->_next.compare_exchange_strong(expected, next, std::memory_order_release, std::memory_order_relaxed)) {
        expected = n;
        // (5) - this release-CAS synchronizes-with the acquire-load (1)
        _tail.compare_exchange_strong(expected, next, std::memory_order_release, std::memory_order_relaxed);
        return;
      }
      next->steal_init_value(value);
      delete next;
    }
  }

  template <class T, class... Policies>
  bool nikolaev_queue<T, Policies...>::try_pop(value_type& result) {
    guard_ptr n;
    for (;;) {
      // (6) - this acquire-load synchronizes-with the release-CAS (8)
      n.acquire(_head, std::memory_order_acquire);
      if (n->try_pop(result))
        return true;
      if (n->_next.load(std::memory_order_relaxed) == nullptr)
        return false;

      n->_allocated_queue.set_threshold(3 * entries_per_node - 1);
      if (n->try_pop(result))
        return true;

      // (7) - this acquire-load synchronizes-with (4)
      const auto next = n->_next.load(std::memory_order_acquire);
      marked_ptr expected = n;
      // (8) - this release-CAS synchronizes-with the acquire-load (6)
      if (_head.compare_exchange_weak(expected, next, std::memory_order_release, std::memory_order_relaxed)) {
        n.reclaim();
      }
    }
  }
}

#endif